**Paper URL:** [arXiv](https://arxiv.org/abs/2408.06292)


## Abstract
**AI Scientist**は、大規模言語モデル（LLM）を活用し、新しい研究アイデアの生成、コードの記述、実験の実行、結果の可視化、論文の執筆、そしてレビューのシミュレーションまでを自動で行う。本手法を機械学習の3つのサブフィールド（拡散モデル、言語モデル、学習ダイナミクス）に適用し、実験的にその有用性を検証した。さらに、自動レビュープロセスを設計し、AI Scientistが生成した論文の品質を評価。結果として、本手法はトップ会議の採択基準を満たす論文を生成可能であることが示された。


## Key Points
- 研究プロセスの自動化
    - AI Scientistは、研究アイデアの生成、コード記述、実験実行、論文執筆、レビューを含む完全な研究プロセスを自動化する。
    - 研究の自動化により、論文1本あたり約15ドルという低コストで実験を実施可能。
- 論文生成と自動レビューの有効性
    - 自動レビューシステムを導入し、AI生成論文の品質を評価。ICLR 2022データセットにおいて、人間のレビュアーと同等の精度を達成。
    - AI Scientistが生成した論文は、トップ会議の受理基準を超える品質を持つものもあった。
- 技術的な課題
    - 実験の信頼性と再現性: AIの生成する論文の信頼性や、実験の再現性についての検討が必要。
     - 生成アイデアの質: 既存研究との重複していたり、実装が困難なアイデアを生成することがある。
     - バグの発生とコードの信頼性: AI Scientistはエラー修正のための自動デバッグ機能を備えているが、意図しないコード生成やLaTexのコンパイルエラーが発生する。
- 倫理的な課題 
	- 科学研究の質の低下: 低品質な論文が大量に生成され、査読プロセスを圧迫するリスク。
	- バイアスのリスク: 学習データに由来するバイアスの可能性、偏った評価
	- 悪用の可能性: 意図せず危険な発見を行うリスク


## Considerations
- アイデア生成
	- 新規性と実装可能性のバランスをどう取るかが難しいところ。
- 実験の再現性
	- 監査エージェントはマストに見える。システムが安定したら、独立した再現実験システムで検証するのが好ましいかも
- コード生成
	- githubリンクがある論文を優先的に参照し、コードを取得すれば、いくらか成功確率は上がる？


## Related Work 
[- [[DOLPHIN Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback]]](https://arxiv.org/abs/2501.03916)


## Labels
#Year-2024  #Auto-Research 
